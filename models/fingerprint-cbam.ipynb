{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2df599",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-12T07:28:37.640234Z",
     "iopub.status.busy": "2025-05-12T07:28:37.640003Z",
     "iopub.status.idle": "2025-05-12T07:57:55.620873Z",
     "shell.execute_reply": "2025-05-12T07:57:55.619998Z"
    },
    "papermill": {
     "duration": 1757.985397,
     "end_time": "2025-05-12T07:57:55.622155",
     "exception": false,
     "start_time": "2025-05-12T07:28:37.636758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 07:28:39.074478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747034919.267560      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747034919.321341      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747034933.710046      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747035000.174287      59 service.cc:148] XLA service 0x7db650003fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747035000.175238      59 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1747035006.484521      59 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1747035045.758502      59 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 6s/step - accuracy: 0.2302 - loss: 2.1514 - val_accuracy: 0.0988 - val_loss: 2.5841\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.7663 - loss: 0.7127 - val_accuracy: 0.0988 - val_loss: 3.6153\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.8689 - loss: 0.3169 - val_accuracy: 0.0988 - val_loss: 4.2949\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.8735 - loss: 0.2942 - val_accuracy: 0.0988 - val_loss: 5.0759\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.9379 - loss: 0.1956 - val_accuracy: 0.0988 - val_loss: 5.5827\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9414 - loss: 0.1815 - val_accuracy: 0.0988 - val_loss: 5.5986\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.9323 - loss: 0.1908 - val_accuracy: 0.0988 - val_loss: 5.5998\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.9344 - loss: 0.1683 - val_accuracy: 0.0988 - val_loss: 4.9873\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.9661 - loss: 0.1029 - val_accuracy: 0.0988 - val_loss: 5.9177\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.9651 - loss: 0.1157 - val_accuracy: 0.0988 - val_loss: 6.7912\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9879 - loss: 0.0339 - val_accuracy: 0.0988 - val_loss: 7.2417\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.9915 - loss: 0.0348 - val_accuracy: 0.0988 - val_loss: 7.1232\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.9833 - loss: 0.0546 - val_accuracy: 0.0988 - val_loss: 7.3627\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.9591 - loss: 0.1538 - val_accuracy: 0.0988 - val_loss: 7.5269\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9531 - loss: 0.1661 - val_accuracy: 0.1111 - val_loss: 4.5583\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.8958 - loss: 0.3541 - val_accuracy: 0.0741 - val_loss: 4.0874\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9660 - loss: 0.1177 - val_accuracy: 0.0988 - val_loss: 6.2684\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9674 - loss: 0.0971 - val_accuracy: 0.0988 - val_loss: 8.0282\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.9923 - loss: 0.0314 - val_accuracy: 0.0988 - val_loss: 6.3129\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9856 - loss: 0.0395 - val_accuracy: 0.0988 - val_loss: 5.4872\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.9952 - loss: 0.0174 - val_accuracy: 0.0988 - val_loss: 5.8297\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 298ms/step - accuracy: 0.9845 - loss: 0.0465 - val_accuracy: 0.0988 - val_loss: 5.6495\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9689 - loss: 0.0980 - val_accuracy: 0.0864 - val_loss: 4.1333\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 234ms/step - accuracy: 0.9407 - loss: 0.2323 - val_accuracy: 0.1235 - val_loss: 4.2387\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.9159 - loss: 0.2977 - val_accuracy: 0.1296 - val_loss: 4.6163\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9520 - loss: 0.1478 - val_accuracy: 0.1235 - val_loss: 5.1218\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.9793 - loss: 0.0760 - val_accuracy: 0.1296 - val_loss: 5.5815\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.9907 - loss: 0.0405 - val_accuracy: 0.1296 - val_loss: 5.3934\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9906 - loss: 0.0416 - val_accuracy: 0.1173 - val_loss: 5.3367\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9955 - loss: 0.0173 - val_accuracy: 0.0988 - val_loss: 5.8046\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9949 - loss: 0.0334 - val_accuracy: 0.0926 - val_loss: 5.8085\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.9618 - loss: 0.1040 - val_accuracy: 0.1049 - val_loss: 6.8360\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.9705 - loss: 0.1129 - val_accuracy: 0.1111 - val_loss: 7.0190\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 298ms/step - accuracy: 0.9091 - loss: 0.2505 - val_accuracy: 0.0988 - val_loss: 8.9070\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9671 - loss: 0.0918 - val_accuracy: 0.1605 - val_loss: 9.2974\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.9572 - loss: 0.2418 - val_accuracy: 0.1914 - val_loss: 8.6721\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 271ms/step - accuracy: 0.9561 - loss: 0.1694 - val_accuracy: 0.1296 - val_loss: 9.8294\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9900 - loss: 0.0455 - val_accuracy: 0.1543 - val_loss: 9.2806\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.9644 - loss: 0.1247 - val_accuracy: 0.1975 - val_loss: 12.1029\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9549 - loss: 0.1033 - val_accuracy: 0.1728 - val_loss: 8.7581\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9575 - loss: 0.1035 - val_accuracy: 0.1914 - val_loss: 8.8181\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9749 - loss: 0.0912 - val_accuracy: 0.1667 - val_loss: 9.6120\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9671 - loss: 0.1137 - val_accuracy: 0.2160 - val_loss: 8.0060\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.9851 - loss: 0.0468 - val_accuracy: 0.2593 - val_loss: 7.8016\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9981 - loss: 0.0175 - val_accuracy: 0.2531 - val_loss: 8.8662\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.9841 - loss: 0.0362 - val_accuracy: 0.2778 - val_loss: 5.7842\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9639 - loss: 0.1228 - val_accuracy: 0.1728 - val_loss: 7.0394\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.9885 - loss: 0.0693 - val_accuracy: 0.1605 - val_loss: 8.5244\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.9661 - loss: 0.0898 - val_accuracy: 0.1728 - val_loss: 8.9010\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.9898 - loss: 0.0254 - val_accuracy: 0.2160 - val_loss: 7.3672\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.9921 - loss: 0.0321 - val_accuracy: 0.2222 - val_loss: 7.1903\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9814 - loss: 0.0748 - val_accuracy: 0.3272 - val_loss: 5.5335\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9669 - loss: 0.1709 - val_accuracy: 0.2346 - val_loss: 4.5171\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.9734 - loss: 0.0680 - val_accuracy: 0.2654 - val_loss: 3.7008\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 271ms/step - accuracy: 0.9526 - loss: 0.1777 - val_accuracy: 0.2901 - val_loss: 4.1543\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9817 - loss: 0.0591 - val_accuracy: 0.2716 - val_loss: 4.3849\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.9862 - loss: 0.0447 - val_accuracy: 0.2593 - val_loss: 6.1077\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.9778 - loss: 0.0425 - val_accuracy: 0.2222 - val_loss: 7.4777\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 270ms/step - accuracy: 0.9883 - loss: 0.0485 - val_accuracy: 0.1481 - val_loss: 8.7036\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.9981 - loss: 0.0115 - val_accuracy: 0.1914 - val_loss: 7.4081\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9993 - loss: 0.0068 - val_accuracy: 0.2160 - val_loss: 6.5725\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.9981 - loss: 0.0173 - val_accuracy: 0.3827 - val_loss: 3.9975\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9958 - loss: 0.0115 - val_accuracy: 0.2593 - val_loss: 7.8020\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.9811 - loss: 0.0653 - val_accuracy: 0.3025 - val_loss: 8.2397\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.9979 - loss: 0.0103 - val_accuracy: 0.3642 - val_loss: 7.5022\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.9902 - loss: 0.0276 - val_accuracy: 0.4198 - val_loss: 5.2153\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.9887 - loss: 0.0296 - val_accuracy: 0.3272 - val_loss: 6.8484\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.9962 - loss: 0.0187 - val_accuracy: 0.4383 - val_loss: 4.4020\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 271ms/step - accuracy: 0.9826 - loss: 0.0394 - val_accuracy: 0.5494 - val_loss: 2.6629\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9977 - loss: 0.0105 - val_accuracy: 0.6975 - val_loss: 1.3783\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9975 - loss: 0.0096 - val_accuracy: 0.8951 - val_loss: 0.4871\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9876 - loss: 0.0328 - val_accuracy: 0.9259 - val_loss: 0.2182\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9728 - loss: 0.0786 - val_accuracy: 0.9444 - val_loss: 0.1933\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9913 - loss: 0.0253 - val_accuracy: 0.8210 - val_loss: 0.6053\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9921 - loss: 0.0284 - val_accuracy: 0.8272 - val_loss: 0.6689\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.9901 - loss: 0.0266 - val_accuracy: 0.7840 - val_loss: 0.8038\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.9575 - loss: 0.1308 - val_accuracy: 0.7716 - val_loss: 0.6631\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.9785 - loss: 0.0666 - val_accuracy: 0.9012 - val_loss: 0.3277\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9865 - loss: 0.0390 - val_accuracy: 0.8333 - val_loss: 0.6189\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.9901 - loss: 0.0356 - val_accuracy: 0.7469 - val_loss: 0.9496\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9728 - loss: 0.0737 - val_accuracy: 0.7284 - val_loss: 1.0646\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9860 - loss: 0.0741 - val_accuracy: 0.7037 - val_loss: 1.2966\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9835 - loss: 0.0703 - val_accuracy: 0.8272 - val_loss: 0.8399\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9929 - loss: 0.0272 - val_accuracy: 0.8580 - val_loss: 0.5342\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.9864 - loss: 0.0292 - val_accuracy: 0.8951 - val_loss: 0.3340\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - accuracy: 0.9977 - loss: 0.0175 - val_accuracy: 0.9568 - val_loss: 0.1366\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.9829 - loss: 0.0397 - val_accuracy: 0.9506 - val_loss: 0.1403\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.9960 - loss: 0.0116 - val_accuracy: 0.9444 - val_loss: 0.1686\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.9568 - val_loss: 0.1813\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.9892 - loss: 0.0291 - val_accuracy: 0.9877 - val_loss: 0.0791\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9594 - loss: 0.1236 - val_accuracy: 0.9815 - val_loss: 0.0595\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.9886 - loss: 0.0204 - val_accuracy: 0.9753 - val_loss: 0.0639\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.9948 - loss: 0.0143 - val_accuracy: 0.9753 - val_loss: 0.0553\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9930 - loss: 0.0176 - val_accuracy: 0.9753 - val_loss: 0.0507\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9691 - val_loss: 0.0451\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9877 - val_loss: 0.0363\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 301ms/step - accuracy: 0.9728 - loss: 0.0673 - val_accuracy: 0.9630 - val_loss: 0.1637\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9910 - loss: 0.0183 - val_accuracy: 0.9506 - val_loss: 0.1689\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9851 - loss: 0.0658 - val_accuracy: 0.9383 - val_loss: 0.1859\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 299ms/step - accuracy: 0.9857 - loss: 0.0442 - val_accuracy: 0.9383 - val_loss: 0.2046\n",
      "Epoch 1/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.1930 - loss: 2.1945 - val_accuracy: 0.0802 - val_loss: 2.3048\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.2862 - loss: 1.8223 - val_accuracy: 0.0802 - val_loss: 2.3102\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.3443 - loss: 1.6157 - val_accuracy: 0.0802 - val_loss: 2.3178\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 272ms/step - accuracy: 0.4002 - loss: 1.4946 - val_accuracy: 0.0802 - val_loss: 2.3318\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 296ms/step - accuracy: 0.4448 - loss: 1.4017 - val_accuracy: 0.0988 - val_loss: 2.3548\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.4101 - loss: 1.4272 - val_accuracy: 0.0988 - val_loss: 2.3803\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - accuracy: 0.4370 - loss: 1.4455 - val_accuracy: 0.0988 - val_loss: 2.4049\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.5214 - loss: 1.2677 - val_accuracy: 0.0988 - val_loss: 2.4419\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.5259 - loss: 1.1820 - val_accuracy: 0.0988 - val_loss: 2.4901\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.4760 - loss: 1.2282 - val_accuracy: 0.0988 - val_loss: 2.5530\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 337ms/step - accuracy: 0.5369 - loss: 1.2305 - val_accuracy: 0.0988 - val_loss: 2.6182\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.5447 - loss: 1.1254 - val_accuracy: 0.0988 - val_loss: 2.7035\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.5219 - loss: 1.2031 - val_accuracy: 0.0988 - val_loss: 2.7857\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.5401 - loss: 1.1306 - val_accuracy: 0.0988 - val_loss: 2.8046\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.6172 - loss: 0.9850 - val_accuracy: 0.1049 - val_loss: 2.9577\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.5083 - loss: 1.1596 - val_accuracy: 0.1049 - val_loss: 3.0554\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 340ms/step - accuracy: 0.6634 - loss: 0.8885 - val_accuracy: 0.1049 - val_loss: 3.2222\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.6008 - loss: 1.0391 - val_accuracy: 0.1049 - val_loss: 3.4210\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.6427 - loss: 0.9168 - val_accuracy: 0.1049 - val_loss: 3.5106\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 332ms/step - accuracy: 0.6435 - loss: 0.9398 - val_accuracy: 0.1049 - val_loss: 3.5346\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 341ms/step - accuracy: 0.6545 - loss: 0.8442 - val_accuracy: 0.1049 - val_loss: 3.6734\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.7087 - loss: 0.7721 - val_accuracy: 0.1049 - val_loss: 3.9007\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 326ms/step - accuracy: 0.7249 - loss: 0.7545 - val_accuracy: 0.1049 - val_loss: 4.1349\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 322ms/step - accuracy: 0.7060 - loss: 0.8185 - val_accuracy: 0.1049 - val_loss: 4.5295\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.6971 - loss: 0.8323 - val_accuracy: 0.1049 - val_loss: 4.5547\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 334ms/step - accuracy: 0.7059 - loss: 0.7575 - val_accuracy: 0.1049 - val_loss: 4.8482\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 338ms/step - accuracy: 0.7598 - loss: 0.6998 - val_accuracy: 0.1049 - val_loss: 5.0903\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.7516 - loss: 0.7123 - val_accuracy: 0.1049 - val_loss: 5.4452\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.7568 - loss: 0.6822 - val_accuracy: 0.1049 - val_loss: 5.3608\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 272ms/step - accuracy: 0.7431 - loss: 0.6298 - val_accuracy: 0.1049 - val_loss: 5.6708\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.7630 - loss: 0.5938 - val_accuracy: 0.1049 - val_loss: 5.6243\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - accuracy: 0.7914 - loss: 0.5726 - val_accuracy: 0.1049 - val_loss: 5.6659\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 298ms/step - accuracy: 0.7789 - loss: 0.5904 - val_accuracy: 0.1049 - val_loss: 5.7296\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - accuracy: 0.8241 - loss: 0.4961 - val_accuracy: 0.1049 - val_loss: 5.8877\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.7769 - loss: 0.5550 - val_accuracy: 0.1049 - val_loss: 6.2927\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.7709 - loss: 0.5730 - val_accuracy: 0.1049 - val_loss: 6.5049\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 328ms/step - accuracy: 0.8226 - loss: 0.4810 - val_accuracy: 0.1049 - val_loss: 6.1576\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 332ms/step - accuracy: 0.7940 - loss: 0.4928 - val_accuracy: 0.1049 - val_loss: 6.9373\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 332ms/step - accuracy: 0.7632 - loss: 0.6297 - val_accuracy: 0.1049 - val_loss: 6.9970\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.7815 - loss: 0.5890 - val_accuracy: 0.1111 - val_loss: 6.5614\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 329ms/step - accuracy: 0.8312 - loss: 0.4687 - val_accuracy: 0.1235 - val_loss: 6.4367\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 331ms/step - accuracy: 0.8145 - loss: 0.5021 - val_accuracy: 0.2346 - val_loss: 6.6011\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 278ms/step - accuracy: 0.8505 - loss: 0.4202 - val_accuracy: 0.1667 - val_loss: 6.9381\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.8601 - loss: 0.3963 - val_accuracy: 0.2284 - val_loss: 6.2155\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 316ms/step - accuracy: 0.8582 - loss: 0.3981 - val_accuracy: 0.1358 - val_loss: 6.6148\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 336ms/step - accuracy: 0.8490 - loss: 0.4007 - val_accuracy: 0.2222 - val_loss: 6.2203\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - accuracy: 0.8324 - loss: 0.4715 - val_accuracy: 0.2222 - val_loss: 5.9919\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.8261 - loss: 0.4593 - val_accuracy: 0.2037 - val_loss: 6.8100\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 339ms/step - accuracy: 0.7900 - loss: 0.5722 - val_accuracy: 0.2099 - val_loss: 4.7319\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8104 - loss: 0.5363 - val_accuracy: 0.2099 - val_loss: 6.0680\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.8342 - loss: 0.4689 - val_accuracy: 0.2222 - val_loss: 5.6994\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 280ms/step - accuracy: 0.8377 - loss: 0.4248 - val_accuracy: 0.2407 - val_loss: 4.5617\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 338ms/step - accuracy: 0.8470 - loss: 0.4132 - val_accuracy: 0.3210 - val_loss: 3.4596\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.8443 - loss: 0.4166 - val_accuracy: 0.2346 - val_loss: 4.6733\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.8480 - loss: 0.4084 - val_accuracy: 0.3272 - val_loss: 4.3776\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 341ms/step - accuracy: 0.8833 - loss: 0.3547 - val_accuracy: 0.1975 - val_loss: 5.9367\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - accuracy: 0.9249 - loss: 0.2536 - val_accuracy: 0.4259 - val_loss: 2.5644\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 322ms/step - accuracy: 0.9106 - loss: 0.2810 - val_accuracy: 0.4506 - val_loss: 1.8555\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - accuracy: 0.8738 - loss: 0.3088 - val_accuracy: 0.4753 - val_loss: 2.0233\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 315ms/step - accuracy: 0.9083 - loss: 0.2839 - val_accuracy: 0.4136 - val_loss: 3.1708\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 334ms/step - accuracy: 0.9126 - loss: 0.2683 - val_accuracy: 0.4630 - val_loss: 2.1804\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - accuracy: 0.8985 - loss: 0.2947 - val_accuracy: 0.3951 - val_loss: 3.6889\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 327ms/step - accuracy: 0.8909 - loss: 0.3258 - val_accuracy: 0.3889 - val_loss: 5.6818\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.8305 - loss: 0.4189 - val_accuracy: 0.3086 - val_loss: 7.4336\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 324ms/step - accuracy: 0.8659 - loss: 0.3583 - val_accuracy: 0.3827 - val_loss: 6.1540\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.9007 - loss: 0.2973 - val_accuracy: 0.6173 - val_loss: 2.5071\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 339ms/step - accuracy: 0.8988 - loss: 0.2938 - val_accuracy: 0.7346 - val_loss: 0.6312\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 327ms/step - accuracy: 0.9317 - loss: 0.2158 - val_accuracy: 0.4691 - val_loss: 1.7141\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 277ms/step - accuracy: 0.9292 - loss: 0.2307 - val_accuracy: 0.5864 - val_loss: 1.5055\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 334ms/step - accuracy: 0.9127 - loss: 0.2208 - val_accuracy: 0.6667 - val_loss: 1.3267\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 321ms/step - accuracy: 0.9331 - loss: 0.2049 - val_accuracy: 0.4568 - val_loss: 5.4141\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 293ms/step - accuracy: 0.9214 - loss: 0.2257 - val_accuracy: 0.8333 - val_loss: 0.4508\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 338ms/step - accuracy: 0.9204 - loss: 0.2173 - val_accuracy: 0.4691 - val_loss: 3.2784\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - accuracy: 0.9076 - loss: 0.2199 - val_accuracy: 0.3580 - val_loss: 5.4630\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.9169 - loss: 0.2405 - val_accuracy: 0.2469 - val_loss: 13.5165\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.9113 - loss: 0.2199 - val_accuracy: 0.4074 - val_loss: 4.6617\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 321ms/step - accuracy: 0.9160 - loss: 0.2280 - val_accuracy: 0.3519 - val_loss: 6.2414\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.9274 - loss: 0.2033 - val_accuracy: 0.2284 - val_loss: 10.9403\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 327ms/step - accuracy: 0.9453 - loss: 0.1666 - val_accuracy: 0.2160 - val_loss: 8.8296\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9092 - loss: 0.2218 - val_accuracy: 0.2531 - val_loss: 11.1639\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.9203 - loss: 0.2193 - val_accuracy: 0.3951 - val_loss: 4.5271\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 327ms/step - accuracy: 0.9580 - loss: 0.1491 - val_accuracy: 0.2654 - val_loss: 8.7211\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.9174 - loss: 0.2301 - val_accuracy: 0.2099 - val_loss: 15.0765\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 327ms/step - accuracy: 0.9122 - loss: 0.2641 - val_accuracy: 0.1420 - val_loss: 15.7303\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.8993 - loss: 0.3002 - val_accuracy: 0.1852 - val_loss: 15.6747\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9008 - loss: 0.2799 - val_accuracy: 0.1728 - val_loss: 14.2604\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 331ms/step - accuracy: 0.9342 - loss: 0.1780 - val_accuracy: 0.2593 - val_loss: 6.4769\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.9039 - loss: 0.2514 - val_accuracy: 0.4630 - val_loss: 7.3252\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - accuracy: 0.9006 - loss: 0.2870 - val_accuracy: 0.3519 - val_loss: 11.4882\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9191 - loss: 0.2390 - val_accuracy: 0.2654 - val_loss: 14.0852\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 332ms/step - accuracy: 0.9216 - loss: 0.2024 - val_accuracy: 0.2778 - val_loss: 9.7795\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 333ms/step - accuracy: 0.9349 - loss: 0.1800 - val_accuracy: 0.5123 - val_loss: 2.7832\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 332ms/step - accuracy: 0.9510 - loss: 0.1642 - val_accuracy: 0.4444 - val_loss: 4.6758\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 328ms/step - accuracy: 0.9531 - loss: 0.1689 - val_accuracy: 0.2593 - val_loss: 12.9381\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.9193 - loss: 0.2328 - val_accuracy: 0.2346 - val_loss: 14.9401\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 335ms/step - accuracy: 0.8997 - loss: 0.2651 - val_accuracy: 0.3395 - val_loss: 9.2012\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 296ms/step - accuracy: 0.9663 - loss: 0.1242 - val_accuracy: 0.2346 - val_loss: 14.3709\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 316ms/step - accuracy: 0.9520 - loss: 0.1428 - val_accuracy: 0.2840 - val_loss: 8.8891\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 321ms/step - accuracy: 0.9480 - loss: 0.1442 - val_accuracy: 0.3580 - val_loss: 7.0091\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.9544 - loss: 0.1429 - val_accuracy: 0.3580 - val_loss: 8.4485\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9318 - loss: 0.1896\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3579 - loss: 8.2250\n",
      "EfficientNet-B0+ Accuracy: 0.9383\n",
      "MobileNet+ Accuracy: 0.3580\n",
      "Đã lưu các mô hình thành công!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, Multiply, Reshape, Layer\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"GPUs detected:\", physical_devices)\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    print(\"No GPUs detected. Running on CPU.\")\n",
    "\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "class CBAMLayer(Layer):\n",
    "    def __init__(self, ratio=8, **kwargs):\n",
    "        super(CBAMLayer, self).__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channel = input_shape[-1]\n",
    "        self.shared_layer_one = Dense(channel // self.ratio, activation='relu')\n",
    "        self.shared_layer_two = Dense(channel)\n",
    "        self.spatial_attention_conv = Conv2D(1, (7, 7), padding='same', activation='sigmoid')\n",
    "        super(CBAMLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        channel = inputs.shape[-1]\n",
    "        avg_pool = GlobalAveragePooling2D()(inputs)\n",
    "        avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "        avg_pool = self.shared_layer_one(avg_pool)\n",
    "        avg_pool = self.shared_layer_two(avg_pool)\n",
    "\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)\n",
    "        max_pool = self.shared_layer_one(max_pool)\n",
    "        max_pool = self.shared_layer_two(max_pool)\n",
    "\n",
    "        channel_attention = tf.keras.activations.sigmoid(avg_pool + max_pool)\n",
    "        channel_refined = Multiply()([inputs, channel_attention])\n",
    "\n",
    "        avg_pool_spatial = tf.reduce_mean(channel_refined, axis=-1, keepdims=True)\n",
    "        max_pool_spatial = tf.reduce_max(channel_refined, axis=-1, keepdims=True)\n",
    "        concat_spatial = tf.concat([avg_pool_spatial, max_pool_spatial], axis=-1)\n",
    "        spatial_attention = self.spatial_attention_conv(concat_spatial)\n",
    "        spatial_refined = Multiply()([channel_refined, spatial_attention])\n",
    "\n",
    "        return spatial_refined\n",
    "\n",
    "def efficientnet_b0_plus(input_shape=(224, 224, 3), num_classes=10):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    x = base_model.get_layer('block7a_project_bn').output\n",
    "    x = CBAMLayer()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='swish')(x)\n",
    "    output = Dense(num_classes, activation='softmax', dtype='float32')(x)  \n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "def mobilenet_plus(input_shape=(224, 224, 3), num_classes=10):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    def inverted_residual_block(x, filters, stride, expansion):\n",
    "        in_channels = x.shape[-1]\n",
    "        x_expanded = Conv2D(expansion * in_channels, (1, 1), padding='same')(x)\n",
    "        x_expanded = layers.BatchNormalization()(x_expanded)\n",
    "        x_expanded = layers.Activation('relu')(x_expanded)\n",
    "        \n",
    "        x_depthwise = layers.DepthwiseConv2D((3, 3), strides=stride, padding='same')(x_expanded)\n",
    "        x_depthwise = layers.BatchNormalization()(x_depthwise)\n",
    "        x_depthwise = layers.Activation('relu')(x_depthwise)\n",
    "        \n",
    "        x_pointwise = Conv2D(filters, (1, 1), padding='same')(x_depthwise)\n",
    "        x_pointwise = layers.BatchNormalization()(x_pointwise)\n",
    "        \n",
    "        x = CBAMLayer()(x_pointwise)\n",
    "        \n",
    "        if stride == 1 and in_channels == filters:\n",
    "            x = layers.Add()([x, x_pointwise])\n",
    "        return x\n",
    "    \n",
    "    x = inverted_residual_block(x, 64, 1, 6)\n",
    "    x = inverted_residual_block(x, 128, 2, 6)\n",
    "    x = inverted_residual_block(x, 128, 1, 6)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(num_classes, activation='softmax', dtype='float32')(x)  \n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    img_train = np.load(os.path.join(data_dir, 'np_data', 'img_train.npy'))\n",
    "    label_train = np.load(os.path.join(data_dir, 'np_data', 'label_train.npy'))\n",
    "    img_real = np.load(os.path.join(data_dir, 'np_data', 'img_real.npy'))\n",
    "    label_real = np.load(os.path.join(data_dir, 'np_data', 'label_real.npy'))\n",
    "    \n",
    "    images = np.concatenate((img_train, img_real), axis=0)\n",
    "    labels = np.concatenate((label_train, label_real), axis=0)\n",
    "    \n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        if img.shape[-1] == 1:\n",
    "            img = np.repeat(img, 3, axis=-1)\n",
    "        img = tf.image.resize(img, [224, 224]).numpy()\n",
    "        processed_images.append(img)\n",
    "    \n",
    "    return np.array(processed_images), labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = '/kaggle/input/fingerprint-dataset-for-fvc2000-db4-b/dataset_FVC2000_DB4_B/dataset'\n",
    "    images, labels = load_and_preprocess_data(data_dir)\n",
    "    \n",
    "    images = images / 255.0\n",
    "    num_classes = len(np.unique(labels))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    effnet_model = efficientnet_b0_plus(num_classes=num_classes)\n",
    "    mobilenet_model = mobilenet_plus(num_classes=num_classes)\n",
    "    \n",
    "    effnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    mobilenet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "    effnet_model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "                     epochs=100, \n",
    "                     validation_data=(X_test, y_test))\n",
    "    \n",
    "    mobilenet_model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "                        epochs=100, \n",
    "                        validation_data=(X_test, y_test))\n",
    "    \n",
    "    effnet_loss, effnet_acc = effnet_model.evaluate(X_test, y_test)\n",
    "    mobilenet_loss, mobilenet_acc = mobilenet_model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(f\"EfficientNet-B0+ Accuracy: {effnet_acc:.4f}\")\n",
    "    print(f\"MobileNet+ Accuracy: {mobilenet_acc:.4f}\")\n",
    "\n",
    "    effnet_model.save('efficientnet_b0_plus.keras')\n",
    "\n",
    "    mobilenet_model.save('mobilenet_plus.keras')\n",
    "\n",
    "    print(\"Đã lưu các mô hình thành công!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 530335,
     "sourceId": 1071804,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1765.998394,
   "end_time": "2025-05-12T07:57:59.523867",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-12T07:28:33.525473",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
