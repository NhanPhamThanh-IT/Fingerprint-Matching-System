{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068bce3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-12T12:10:08.435202Z",
     "iopub.status.busy": "2025-05-12T12:10:08.434907Z",
     "iopub.status.idle": "2025-05-12T12:39:42.589324Z",
     "shell.execute_reply": "2025-05-12T12:39:42.588505Z"
    },
    "papermill": {
     "duration": 1774.158844,
     "end_time": "2025-05-12T12:39:42.590712",
     "exception": false,
     "start_time": "2025-05-12T12:10:08.431868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 12:10:10.180079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747051810.390026      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747051810.449712      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747051825.538001      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747051891.659302      57 service.cc:148] XLA service 0x7a8cec005280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747051891.660290      57 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1747051897.793571      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1747051938.865217      57 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 6s/step - accuracy: 0.1928 - loss: 2.1692 - val_accuracy: 0.0988 - val_loss: 2.7777\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 234ms/step - accuracy: 0.7690 - loss: 0.7169 - val_accuracy: 0.0988 - val_loss: 3.1343\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 301ms/step - accuracy: 0.9148 - loss: 0.2849 - val_accuracy: 0.0988 - val_loss: 4.4758\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - accuracy: 0.9405 - loss: 0.1763 - val_accuracy: 0.0988 - val_loss: 7.6624\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 231ms/step - accuracy: 0.9349 - loss: 0.1624 - val_accuracy: 0.0988 - val_loss: 6.7117\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.9578 - loss: 0.1376 - val_accuracy: 0.0988 - val_loss: 5.8197\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.9598 - loss: 0.1735 - val_accuracy: 0.0988 - val_loss: 5.7072\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.9708 - loss: 0.1185 - val_accuracy: 0.0988 - val_loss: 5.6885\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9413 - loss: 0.1283 - val_accuracy: 0.1049 - val_loss: 3.5790\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9772 - loss: 0.0687 - val_accuracy: 0.0988 - val_loss: 4.5917\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 295ms/step - accuracy: 0.9750 - loss: 0.0919 - val_accuracy: 0.0988 - val_loss: 5.8308\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.9812 - loss: 0.0699 - val_accuracy: 0.0864 - val_loss: 6.6366\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9866 - loss: 0.0401 - val_accuracy: 0.0988 - val_loss: 11.7066\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9792 - loss: 0.0428 - val_accuracy: 0.0988 - val_loss: 13.0819\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.9912 - loss: 0.0230 - val_accuracy: 0.0988 - val_loss: 10.2232\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.9741 - loss: 0.0660 - val_accuracy: 0.0988 - val_loss: 6.8666\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.9608 - loss: 0.1133 - val_accuracy: 0.0926 - val_loss: 4.9405\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9728 - loss: 0.1042 - val_accuracy: 0.0864 - val_loss: 5.6924\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.8965 - loss: 0.3189 - val_accuracy: 0.0617 - val_loss: 6.0048\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9067 - loss: 0.2371 - val_accuracy: 0.0988 - val_loss: 6.6018\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 227ms/step - accuracy: 0.9108 - loss: 0.2681 - val_accuracy: 0.0988 - val_loss: 12.1571\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9645 - loss: 0.1271 - val_accuracy: 0.0988 - val_loss: 13.9116\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 291ms/step - accuracy: 0.9663 - loss: 0.1292 - val_accuracy: 0.0988 - val_loss: 11.0575\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9786 - loss: 0.0734 - val_accuracy: 0.0988 - val_loss: 8.1902\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9946 - loss: 0.0405 - val_accuracy: 0.0988 - val_loss: 8.3739\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9586 - loss: 0.1288 - val_accuracy: 0.0988 - val_loss: 9.6499\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9813 - loss: 0.0601 - val_accuracy: 0.1049 - val_loss: 8.0178\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - accuracy: 0.9783 - loss: 0.1044 - val_accuracy: 0.1296 - val_loss: 4.7014\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9873 - loss: 0.0389 - val_accuracy: 0.0988 - val_loss: 6.5375\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 293ms/step - accuracy: 0.9582 - loss: 0.1442 - val_accuracy: 0.1111 - val_loss: 7.8460\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.9752 - loss: 0.0748 - val_accuracy: 0.1173 - val_loss: 7.0285\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9896 - loss: 0.0348 - val_accuracy: 0.1173 - val_loss: 5.6972\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9971 - loss: 0.0116 - val_accuracy: 0.1235 - val_loss: 5.8226\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9868 - loss: 0.0630 - val_accuracy: 0.0988 - val_loss: 6.0251\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.9950 - loss: 0.0183 - val_accuracy: 0.1049 - val_loss: 6.1654\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.9939 - loss: 0.0187 - val_accuracy: 0.1111 - val_loss: 5.6100\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.9916 - loss: 0.0295 - val_accuracy: 0.1111 - val_loss: 5.0971\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9904 - loss: 0.0232 - val_accuracy: 0.1235 - val_loss: 3.5212\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.9870 - loss: 0.0459 - val_accuracy: 0.1111 - val_loss: 4.1919\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9870 - loss: 0.0489 - val_accuracy: 0.1235 - val_loss: 3.7897\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.9876 - loss: 0.0428 - val_accuracy: 0.1173 - val_loss: 4.2468\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.9927 - loss: 0.0389 - val_accuracy: 0.1235 - val_loss: 4.9107\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.9800 - loss: 0.0835 - val_accuracy: 0.1605 - val_loss: 5.1379\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.9415 - loss: 0.1925 - val_accuracy: 0.1852 - val_loss: 5.2647\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9629 - loss: 0.1170 - val_accuracy: 0.1543 - val_loss: 4.1659\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9679 - loss: 0.0924 - val_accuracy: 0.2284 - val_loss: 4.0415\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9953 - loss: 0.0269 - val_accuracy: 0.1235 - val_loss: 7.3604\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9861 - loss: 0.0382 - val_accuracy: 0.1235 - val_loss: 10.0059\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 274ms/step - accuracy: 0.9897 - loss: 0.0487 - val_accuracy: 0.1296 - val_loss: 9.3686\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9951 - loss: 0.0286 - val_accuracy: 0.1235 - val_loss: 8.6854\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9872 - loss: 0.0476 - val_accuracy: 0.1420 - val_loss: 7.8716\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9881 - loss: 0.0425 - val_accuracy: 0.1296 - val_loss: 7.1909\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.9884 - loss: 0.0325 - val_accuracy: 0.1235 - val_loss: 7.0105\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9904 - loss: 0.0295 - val_accuracy: 0.1296 - val_loss: 6.7784\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 279ms/step - accuracy: 0.9878 - loss: 0.0293 - val_accuracy: 0.1914 - val_loss: 6.5501\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.9885 - loss: 0.0558 - val_accuracy: 0.1358 - val_loss: 8.3280\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 280ms/step - accuracy: 0.9802 - loss: 0.0451 - val_accuracy: 0.1481 - val_loss: 7.5882\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.9927 - loss: 0.0258 - val_accuracy: 0.1605 - val_loss: 6.8591\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9832 - loss: 0.0454 - val_accuracy: 0.2654 - val_loss: 4.3270\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.9774 - loss: 0.0933 - val_accuracy: 0.3827 - val_loss: 2.9879\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 296ms/step - accuracy: 0.9988 - loss: 0.0171 - val_accuracy: 0.3951 - val_loss: 3.0008\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 289ms/step - accuracy: 0.9949 - loss: 0.0181 - val_accuracy: 0.3457 - val_loss: 3.3297\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.9915 - loss: 0.0328 - val_accuracy: 0.3519 - val_loss: 3.3900\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.9954 - loss: 0.0148 - val_accuracy: 0.3333 - val_loss: 3.6627\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.9927 - loss: 0.0236 - val_accuracy: 0.3704 - val_loss: 3.9171\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.9951 - loss: 0.0178 - val_accuracy: 0.3951 - val_loss: 3.9674\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9942 - loss: 0.0198 - val_accuracy: 0.4506 - val_loss: 3.4556\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.9739 - loss: 0.1117 - val_accuracy: 0.4012 - val_loss: 3.7075\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9865 - loss: 0.0532 - val_accuracy: 0.3210 - val_loss: 4.6572\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - accuracy: 0.9935 - loss: 0.0275 - val_accuracy: 0.2160 - val_loss: 10.5490\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - accuracy: 0.9905 - loss: 0.0502 - val_accuracy: 0.2531 - val_loss: 11.6095\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9941 - loss: 0.0198 - val_accuracy: 0.3827 - val_loss: 7.5270\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.9937 - loss: 0.0234 - val_accuracy: 0.6173 - val_loss: 3.2380\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 282ms/step - accuracy: 0.9990 - loss: 0.0086 - val_accuracy: 0.8086 - val_loss: 1.2893\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 0.8642 - val_loss: 0.6186\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.9994 - loss: 0.0097 - val_accuracy: 0.9444 - val_loss: 0.2614\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.9980 - loss: 0.0087 - val_accuracy: 0.9259 - val_loss: 0.4326\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.9788 - loss: 0.0562 - val_accuracy: 0.7716 - val_loss: 1.0847\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - accuracy: 0.9863 - loss: 0.0544 - val_accuracy: 0.8827 - val_loss: 0.5030\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 281ms/step - accuracy: 0.9516 - loss: 0.1672 - val_accuracy: 0.8395 - val_loss: 0.5991\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.9642 - loss: 0.0956 - val_accuracy: 0.7469 - val_loss: 0.9616\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.9787 - loss: 0.0720 - val_accuracy: 0.7716 - val_loss: 0.9317\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 286ms/step - accuracy: 0.9738 - loss: 0.1199 - val_accuracy: 0.5556 - val_loss: 2.0665\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9796 - loss: 0.0856 - val_accuracy: 0.4506 - val_loss: 2.6803\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 302ms/step - accuracy: 0.9792 - loss: 0.0614 - val_accuracy: 0.3642 - val_loss: 2.9558\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.9852 - loss: 0.0725 - val_accuracy: 0.5802 - val_loss: 2.0888\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 283ms/step - accuracy: 0.9924 - loss: 0.0240 - val_accuracy: 0.6296 - val_loss: 1.6849\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 226ms/step - accuracy: 0.9941 - loss: 0.0212 - val_accuracy: 0.7222 - val_loss: 1.3562\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.9939 - loss: 0.0171 - val_accuracy: 0.7099 - val_loss: 1.5087\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 295ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.7099 - val_loss: 1.7593\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 290ms/step - accuracy: 0.9948 - loss: 0.0137 - val_accuracy: 0.6481 - val_loss: 2.2119\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - accuracy: 0.9831 - loss: 0.0836 - val_accuracy: 0.6235 - val_loss: 1.9161\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.9722 - loss: 0.0772 - val_accuracy: 0.7284 - val_loss: 1.3952\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.9751 - loss: 0.0908 - val_accuracy: 0.6852 - val_loss: 1.4597\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.9752 - loss: 0.0632 - val_accuracy: 0.8395 - val_loss: 0.6060\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9937 - loss: 0.0241 - val_accuracy: 0.8395 - val_loss: 0.5690\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.9899 - loss: 0.0343 - val_accuracy: 0.8519 - val_loss: 0.5202\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.9993 - loss: 0.0101 - val_accuracy: 0.9321 - val_loss: 0.2786\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.9892 - loss: 0.0342 - val_accuracy: 0.7963 - val_loss: 0.9027\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.9806 - loss: 0.0512 - val_accuracy: 0.9444 - val_loss: 0.1257\n",
      "Epoch 1/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.1574 - loss: 2.2729 - val_accuracy: 0.0988 - val_loss: 2.3021\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 330ms/step - accuracy: 0.3771 - loss: 1.6662 - val_accuracy: 0.0988 - val_loss: 2.3057\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.3980 - loss: 1.5174 - val_accuracy: 0.0988 - val_loss: 2.3155\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.4400 - loss: 1.3658 - val_accuracy: 0.0988 - val_loss: 2.3393\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.4609 - loss: 1.3696 - val_accuracy: 0.0988 - val_loss: 2.3684\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 339ms/step - accuracy: 0.4607 - loss: 1.4042 - val_accuracy: 0.0988 - val_loss: 2.4039\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.4935 - loss: 1.2384 - val_accuracy: 0.0988 - val_loss: 2.4433\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.5408 - loss: 1.1551 - val_accuracy: 0.0988 - val_loss: 2.4950\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 316ms/step - accuracy: 0.5395 - loss: 1.1201 - val_accuracy: 0.0988 - val_loss: 2.5417\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.5805 - loss: 1.0800 - val_accuracy: 0.0988 - val_loss: 2.6272\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 322ms/step - accuracy: 0.5434 - loss: 1.1346 - val_accuracy: 0.0802 - val_loss: 2.7265\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 278ms/step - accuracy: 0.5131 - loss: 1.1567 - val_accuracy: 0.0802 - val_loss: 2.8111\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.5817 - loss: 1.0317 - val_accuracy: 0.0802 - val_loss: 2.9049\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.5493 - loss: 1.0253 - val_accuracy: 0.0802 - val_loss: 3.0026\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.6528 - loss: 0.9551 - val_accuracy: 0.0802 - val_loss: 3.1655\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 331ms/step - accuracy: 0.6284 - loss: 0.9466 - val_accuracy: 0.0802 - val_loss: 3.3684\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.6130 - loss: 0.9363 - val_accuracy: 0.0802 - val_loss: 3.5603\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.6288 - loss: 0.9104 - val_accuracy: 0.0802 - val_loss: 3.5688\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.6718 - loss: 0.8757 - val_accuracy: 0.0802 - val_loss: 3.7418\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.7086 - loss: 0.9073 - val_accuracy: 0.0802 - val_loss: 3.7169\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 324ms/step - accuracy: 0.6894 - loss: 0.8436 - val_accuracy: 0.0802 - val_loss: 4.0871\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 337ms/step - accuracy: 0.6888 - loss: 0.8294 - val_accuracy: 0.0802 - val_loss: 4.3049\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 339ms/step - accuracy: 0.6776 - loss: 0.8706 - val_accuracy: 0.0802 - val_loss: 4.2662\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.6295 - loss: 0.9083 - val_accuracy: 0.0802 - val_loss: 4.3748\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.7115 - loss: 0.7413 - val_accuracy: 0.0802 - val_loss: 4.4254\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 263ms/step - accuracy: 0.6636 - loss: 0.8292 - val_accuracy: 0.0802 - val_loss: 4.3483\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.7035 - loss: 0.7586 - val_accuracy: 0.0802 - val_loss: 5.0815\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 322ms/step - accuracy: 0.7103 - loss: 0.7436 - val_accuracy: 0.0802 - val_loss: 5.5621\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.7288 - loss: 0.7021 - val_accuracy: 0.0802 - val_loss: 5.9231\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.7563 - loss: 0.6626 - val_accuracy: 0.0802 - val_loss: 5.9801\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 330ms/step - accuracy: 0.7485 - loss: 0.6786 - val_accuracy: 0.0802 - val_loss: 6.6069\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 334ms/step - accuracy: 0.7206 - loss: 0.7419 - val_accuracy: 0.0802 - val_loss: 6.4940\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 313ms/step - accuracy: 0.7787 - loss: 0.6328 - val_accuracy: 0.0802 - val_loss: 7.2225\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.6986 - loss: 0.7708 - val_accuracy: 0.0802 - val_loss: 7.6334\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.7072 - loss: 0.7135 - val_accuracy: 0.0802 - val_loss: 8.1427\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 326ms/step - accuracy: 0.7326 - loss: 0.6769 - val_accuracy: 0.0802 - val_loss: 7.6340\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.7739 - loss: 0.6076 - val_accuracy: 0.1049 - val_loss: 7.5913\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 340ms/step - accuracy: 0.7997 - loss: 0.5187 - val_accuracy: 0.0802 - val_loss: 8.1933\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 335ms/step - accuracy: 0.8401 - loss: 0.4820 - val_accuracy: 0.0864 - val_loss: 9.6472\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 322ms/step - accuracy: 0.7485 - loss: 0.6130 - val_accuracy: 0.0556 - val_loss: 9.1679\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.7736 - loss: 0.5666 - val_accuracy: 0.0926 - val_loss: 9.8296\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.8194 - loss: 0.5281 - val_accuracy: 0.0802 - val_loss: 11.5918\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.8256 - loss: 0.4462 - val_accuracy: 0.0802 - val_loss: 12.8987\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 317ms/step - accuracy: 0.8112 - loss: 0.5285 - val_accuracy: 0.0988 - val_loss: 7.6204\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 317ms/step - accuracy: 0.8244 - loss: 0.4834 - val_accuracy: 0.1049 - val_loss: 8.5989\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.8222 - loss: 0.4659 - val_accuracy: 0.1111 - val_loss: 7.3045\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 319ms/step - accuracy: 0.8540 - loss: 0.4076 - val_accuracy: 0.0741 - val_loss: 8.6573\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 273ms/step - accuracy: 0.8233 - loss: 0.5206 - val_accuracy: 0.0802 - val_loss: 12.9482\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 316ms/step - accuracy: 0.7944 - loss: 0.5383 - val_accuracy: 0.0864 - val_loss: 6.9781\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8159 - loss: 0.4975 - val_accuracy: 0.1852 - val_loss: 5.8710\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.8065 - loss: 0.4987 - val_accuracy: 0.1420 - val_loss: 6.0908\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 258ms/step - accuracy: 0.8751 - loss: 0.3768 - val_accuracy: 0.1605 - val_loss: 5.7017\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.8452 - loss: 0.4120 - val_accuracy: 0.2037 - val_loss: 7.2106\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.8408 - loss: 0.4366 - val_accuracy: 0.1358 - val_loss: 11.4575\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 326ms/step - accuracy: 0.8689 - loss: 0.3665 - val_accuracy: 0.1667 - val_loss: 8.9939\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 316ms/step - accuracy: 0.8524 - loss: 0.4036 - val_accuracy: 0.2407 - val_loss: 6.1540\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.8396 - loss: 0.3915 - val_accuracy: 0.4074 - val_loss: 2.2369\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 338ms/step - accuracy: 0.8539 - loss: 0.4566 - val_accuracy: 0.2901 - val_loss: 6.3435\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.8402 - loss: 0.4488 - val_accuracy: 0.3148 - val_loss: 5.5296\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.8707 - loss: 0.4116 - val_accuracy: 0.6111 - val_loss: 1.1379\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.8715 - loss: 0.3775 - val_accuracy: 0.4630 - val_loss: 2.9780\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.8981 - loss: 0.3129 - val_accuracy: 0.4568 - val_loss: 2.8730\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.8876 - loss: 0.3472 - val_accuracy: 0.2407 - val_loss: 5.9498\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 317ms/step - accuracy: 0.8942 - loss: 0.3108 - val_accuracy: 0.1914 - val_loss: 17.7958\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 322ms/step - accuracy: 0.8878 - loss: 0.2820 - val_accuracy: 0.3086 - val_loss: 4.4748\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 286ms/step - accuracy: 0.8847 - loss: 0.3141 - val_accuracy: 0.2716 - val_loss: 7.8034\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.9154 - loss: 0.2554 - val_accuracy: 0.3025 - val_loss: 6.4693\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.9137 - loss: 0.2578 - val_accuracy: 0.2222 - val_loss: 11.1586\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.8909 - loss: 0.2945 - val_accuracy: 0.4568 - val_loss: 3.8586\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.7968 - loss: 0.4799 - val_accuracy: 0.1235 - val_loss: 38.9631\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.8986 - loss: 0.2949 - val_accuracy: 0.1049 - val_loss: 31.1516\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.8841 - loss: 0.3089 - val_accuracy: 0.1543 - val_loss: 13.0781\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.8839 - loss: 0.3169 - val_accuracy: 0.1667 - val_loss: 17.2566\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 329ms/step - accuracy: 0.9298 - loss: 0.2323 - val_accuracy: 0.6358 - val_loss: 1.5607\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 324ms/step - accuracy: 0.9341 - loss: 0.2382 - val_accuracy: 0.2531 - val_loss: 10.0155\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.8963 - loss: 0.2936 - val_accuracy: 0.2963 - val_loss: 5.2178\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 313ms/step - accuracy: 0.9170 - loss: 0.2567 - val_accuracy: 0.1914 - val_loss: 13.8937\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 321ms/step - accuracy: 0.8736 - loss: 0.3202 - val_accuracy: 0.1049 - val_loss: 57.6003\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 324ms/step - accuracy: 0.8580 - loss: 0.3315 - val_accuracy: 0.1049 - val_loss: 57.0218\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.8738 - loss: 0.3577 - val_accuracy: 0.2716 - val_loss: 11.3109\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.8785 - loss: 0.3347 - val_accuracy: 0.3951 - val_loss: 5.7464\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.8980 - loss: 0.2718 - val_accuracy: 0.1296 - val_loss: 16.2569\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 291ms/step - accuracy: 0.8717 - loss: 0.3724 - val_accuracy: 0.5000 - val_loss: 2.5494\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.9016 - loss: 0.2948 - val_accuracy: 0.6173 - val_loss: 1.8289\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.8967 - loss: 0.2969 - val_accuracy: 0.1605 - val_loss: 24.2068\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.9236 - loss: 0.2231 - val_accuracy: 0.3457 - val_loss: 8.1793\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - accuracy: 0.8935 - loss: 0.3035 - val_accuracy: 0.1420 - val_loss: 21.3130\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 336ms/step - accuracy: 0.8786 - loss: 0.3251 - val_accuracy: 0.4877 - val_loss: 2.9330\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.8818 - loss: 0.2959 - val_accuracy: 0.4630 - val_loss: 3.3849\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 338ms/step - accuracy: 0.8664 - loss: 0.3271 - val_accuracy: 0.4630 - val_loss: 4.1285\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 335ms/step - accuracy: 0.9243 - loss: 0.2328 - val_accuracy: 0.4506 - val_loss: 3.1128\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 275ms/step - accuracy: 0.9229 - loss: 0.2091 - val_accuracy: 0.2778 - val_loss: 19.8570\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 344ms/step - accuracy: 0.8728 - loss: 0.3489 - val_accuracy: 0.4444 - val_loss: 3.2510\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.9342 - loss: 0.2103 - val_accuracy: 0.7099 - val_loss: 1.0478\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 341ms/step - accuracy: 0.9282 - loss: 0.2064 - val_accuracy: 0.2222 - val_loss: 23.3634\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.9445 - loss: 0.2009 - val_accuracy: 0.3642 - val_loss: 16.2004\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 341ms/step - accuracy: 0.8949 - loss: 0.3066 - val_accuracy: 0.1111 - val_loss: 57.5881\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 336ms/step - accuracy: 0.9474 - loss: 0.1856 - val_accuracy: 0.1173 - val_loss: 50.7691\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.9290 - loss: 0.1960 - val_accuracy: 0.2716 - val_loss: 15.5404\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 276ms/step - accuracy: 0.9606 - loss: 0.1492 - val_accuracy: 0.4383 - val_loss: 3.8929\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9623 - loss: 0.1014\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4359 - loss: 3.8606\n",
      "EfficientNet-B0+ Accuracy: 0.9444\n",
      "MobileNet+ Accuracy: 0.4383\n",
      "Đã lưu các mô hình thành công!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, Multiply, Reshape, Layer\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"GPUs detected:\", physical_devices)\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    print(\"No GPUs detected. Running on CPU.\")\n",
    "\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "class SENetLayer(Layer):\n",
    "    def __init__(self, ratio=16, **kwargs):\n",
    "        super(SENetLayer, self).__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channel = input_shape[-1]\n",
    "        self.squeeze = GlobalAveragePooling2D()\n",
    "        self.excitation = tf.keras.Sequential([\n",
    "            Dense(channel // self.ratio, activation='relu'),\n",
    "            Dense(channel, activation='sigmoid')\n",
    "        ])\n",
    "        super(SENetLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        squeezed = self.squeeze(inputs)\n",
    "        squeezed = tf.expand_dims(tf.expand_dims(squeezed, 1), 1)\n",
    "        \n",
    "        excitation = self.excitation(squeezed)\n",
    "        \n",
    "        scaled = Multiply()([inputs, excitation])\n",
    "        return scaled\n",
    "\n",
    "def efficientnet_b0_plus(input_shape=(224, 224, 3), num_classes=10):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    x = base_model.get_layer('block7a_project_bn').output\n",
    "    x = SENetLayer()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='swish')(x)\n",
    "    output = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "def mobilenet_plus(input_shape=(224, 224, 3), num_classes=10):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    def inverted_residual_block(x, filters, stride, expansion):\n",
    "        in_channels = x.shape[-1]\n",
    "        x_expanded = Conv2D(expansion * in_channels, (1, 1), padding='same')(x)\n",
    "        x_expanded = layers.BatchNormalization()(x_expanded)\n",
    "        x_expanded = layers.Activation('relu')(x_expanded)\n",
    "        \n",
    "        x_depthwise = layers.DepthwiseConv2D((3, 3), strides=stride, padding='same')(x_expanded)\n",
    "        x_depthwise = layers.BatchNormalization()(x_depthwise)\n",
    "        x_depthwise = layers.Activation('relu')(x_depthwise)\n",
    "        \n",
    "        x_pointwise = Conv2D(filters, (1, 1), padding='same')(x_depthwise)\n",
    "        x_pointwise = layers.BatchNormalization()(x_pointwise)\n",
    "        \n",
    "        x = SENetLayer()(x_pointwise)\n",
    "        \n",
    "        if stride == 1 and in_channels == filters:\n",
    "            x = layers.Add()([x, x_pointwise])\n",
    "        return x\n",
    "    \n",
    "    x = inverted_residual_block(x, 64, 1, 6)\n",
    "    x = inverted_residual_block(x, 128, 2, 6)\n",
    "    x = inverted_residual_block(x, 128, 1, 6)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    img_train = np.load(os.path.join(data_dir, 'np_data', 'img_train.npy'))\n",
    "    label_train = np.load(os.path.join(data_dir, 'np_data', 'label_train.npy'))\n",
    "    img_real = np.load(os.path.join(data_dir, 'np_data', 'img_real.npy'))\n",
    "    label_real = np.load(os.path.join(data_dir, 'np_data', 'label_real.npy'))\n",
    "    \n",
    "    images = np.concatenate((img_train, img_real), axis=0)\n",
    "    labels = np.concatenate((label_train, label_real), axis=0)\n",
    "    \n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        if img.shape[-1] == 1:\n",
    "            img = np.repeat(img, 3, axis=-1)\n",
    "        img = tf.image.resize(img, [224, 224]).numpy()\n",
    "        processed_images.append(img)\n",
    "    \n",
    "    return np.array(processed_images), labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = '/kaggle/input/fingerprint-dataset-for-fvc2000-db4-b/dataset_FVC2000_DB4_B/dataset'\n",
    "    images, labels = load_and_preprocess_data(data_dir)\n",
    "    \n",
    "    images = images / 255.0\n",
    "    num_classes = len(np.unique(labels))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    effnet_model = efficientnet_b0_plus(num_classes=num_classes)\n",
    "    mobilenet_model = mobilenet_plus(num_classes=num_classes)\n",
    "    \n",
    "    effnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    mobilenet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "    effnet_model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "                     epochs=100, \n",
    "                     validation_data=(X_test, y_test))\n",
    "    \n",
    "    mobilenet_model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "                        epochs=100, \n",
    "                        validation_data=(X_test, y_test))\n",
    "    \n",
    "    effnet_loss, effnet_acc = effnet_model.evaluate(X_test, y_test)\n",
    "    mobilenet_loss, mobilenet_acc = mobilenet_model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(f\"EfficientNet-B0+ Accuracy: {effnet_acc:.4f}\")\n",
    "    print(f\"MobileNet+ Accuracy: {mobilenet_acc:.4f}\")\n",
    "\n",
    "    effnet_model.save('efficientnet_b0_plus.h5')\n",
    "\n",
    "    mobilenet_model.save('mobilenet_plus.h5')\n",
    "\n",
    "    print(\"Đã lưu các mô hình thành công!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 530335,
     "sourceId": 1071804,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1782.032313,
   "end_time": "2025-05-12T12:39:46.372991",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-12T12:10:04.340678",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
